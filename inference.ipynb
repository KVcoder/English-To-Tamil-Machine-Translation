{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "from transformer import create_padding_mask\n",
    "from transformer import create_causal_mask\n",
    "from transformer import combine_masks\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<SOS>'\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "END_TOKEN = '<EOS>'\n",
    "UNKNOWN_TOKEN = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_vocab = [PADDING_TOKEN, START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
    "            'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ', 'க்', 'க', 'கா', 'கி', 'கீ', 'கு', 'கூ', 'கெ', \n",
    "            'கே', 'கை', 'கொ', 'கோ', 'கௌ', 'ங்', 'ங', 'ஙா', 'ஙி', 'ஙீ', 'ஙு', 'ஙூ', 'ஙெ', 'ஙே', 'ஙை', 'ஙொ', 'ஙோ', 'ஙௌ', 'ச்', \n",
    "            'ச', 'சா', 'சி', 'சீ', 'சு', 'சூ', 'செ', 'சே', 'சை', 'சொ', 'சோ', 'சௌ',\n",
    "            'ஞ்', 'ஞ', 'ஞா', 'ஞி', 'ஞீ', 'ஞு', 'ஞூ', 'ஞெ', 'ஞே', 'ஞை', 'ஞொ', 'ஞோ', 'ஞௌ',\n",
    "            'ட்', 'ட', 'டா', 'டி', 'டீ', 'டு', 'டூ', 'டெ', 'டே', 'டை', 'டொ', 'டோ', 'டௌ',\n",
    "            'ண்', 'ண', 'ணா', 'ணி', 'ணீ', 'ணு', 'ணூ', 'ணெ', 'ணே', 'ணை', 'ணொ', 'ணோ', 'ணௌ',\n",
    "            'த்', 'த', 'தா', 'தி', 'தீ', 'து', 'தூ', 'தெ', 'தே', 'தை', 'தொ', 'தோ', 'தௌ',\n",
    "            'ந்', 'ந', 'நா', 'நி', 'நீ', 'நு', 'நூ', 'நெ', 'நே', 'நை', 'நொ', 'நோ', 'நௌ',\n",
    "            'ப்', 'ப', 'பா', 'பி', 'பீ', 'பு', 'பூ', 'பெ', 'பே', 'பை', 'பொ', 'போ', 'பௌ',\n",
    "            'ம்', 'ம', 'மா', 'மி', 'மீ', 'மு', 'மூ', 'மெ', 'மே', 'மை', 'மொ', 'மோ', 'மௌ',\n",
    "            'ய்', 'ய', 'யா', 'யி', 'யீ', 'யு', 'யூ', 'யெ', 'யே', 'யை', 'யொ', 'யோ', 'யௌ',\n",
    "            'ர்', 'ர', 'ரா', 'ரி', 'ரீ', 'ரு', 'ரூ', 'ரெ', 'ரே', 'ரை', 'ரொ', 'ரோ', 'ரௌ',\n",
    "            'ல்', 'ல', 'லா', 'லி', 'லீ', 'லு', 'லூ', 'லெ', 'லே', 'லை', 'லொ', 'லோ', 'லௌ',\n",
    "            'வ்', 'வ', 'வா', 'வி', 'வீ', 'வு', 'வூ', 'வெ', 'வே', 'வை', 'வொ', 'வோ', 'வௌ',\n",
    "            'ழ்', 'ழ', 'ழா', 'ழி', 'ழீ', 'ழு', 'ழூ', 'ழெ', 'ழே', 'ழை', 'ழொ', 'ழோ', 'ழௌ',\n",
    "            'ள்', 'ள', 'ளா', 'ளி', 'ளீ', 'ளு', 'ளூ', 'ளெ', 'ளே', 'ளை', 'ளொ', 'ளோ', 'ளௌ',\n",
    "            'ற்', 'ற', 'றா', 'றி', 'றீ', 'று', 'றூ', 'றெ', 'றே', 'றை', 'றொ', 'றோ', 'றௌ',\n",
    "            'ன்', 'ன', 'னா', 'னி', 'னீ', 'னு', 'னூ', 'னெ', 'னே', 'னை',\n",
    "            'ஶ்', 'ஶ', 'ஶா', 'ஶி', 'ஶீ', 'ஶு', 'ஶூ', 'ஶெ', 'ஶே', 'ஶை', 'ஶொ', 'ஶோ', 'ஶௌ',\n",
    "            'ஜ்', 'ஜ', 'ஜா', 'ஜி', 'ஜீ', 'ஜு', 'ஜூ', 'ஜெ', 'ஜே', 'ஜை', 'ஜொ', 'ஜோ', 'ஜௌ',\n",
    "            'ஷ்', 'ஷ', 'ஷா', 'ஷி', 'ஷீ', 'ஷு', 'ஷூ', 'ஷெ', 'ஷே', 'ஷை', 'ஷொ', 'ஷோ', 'ஷௌ',\n",
    "            'ஸ்', 'ஸ', 'ஸா', 'ஸி', 'ஸீ', 'ஸு', 'ஸூ', 'ஸெ', 'ஸே', 'ஸை', 'ஸொ', 'ஸோ', 'ஸௌ',\n",
    "            'ஹ்', 'ஹ', 'ஹா', 'ஹி', 'ஹீ', 'ஹு', 'ஹூ', 'ஹெ', 'ஹே', 'ஹை', 'ஹொ', 'ஹோ', 'ஹௌ',\n",
    "            'க்ஷ்', 'க்ஷ', 'க்ஷா', 'க்ஷ', 'க்ஷீ', 'க்ஷு', 'க்ஷூ', 'க்ஷெ', 'க்ஷே', 'க்ஷை', 'க்ஷொ', 'க்ஷோ', 'க்ஷௌ', \n",
    "            '்', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ',END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = [PADDING_TOKEN, START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@',\n",
    "                        '[', '\\\\', ']', '^', '_', '`', \n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', '{', '|', '}', '~', END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_tamil = {k:v for k,v in enumerate(ta_vocab)}\n",
    "tamil_to_index = {v:k for k,v in enumerate(ta_vocab)}\n",
    "index_to_english = {k:v for k,v in enumerate(en_vocab)}\n",
    "english_to_index = {v:k for k,v in enumerate(en_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en-ta/English.txt', 'r') as file:\n",
    "    en_sentences = file.readlines()\n",
    "with open('en-ta/Tamil.txt', 'r') as file:\n",
    "    ta_sentences = file.readlines()\n",
    "\n",
    "TOTAL_SENTENCES = 200000\n",
    "en_sentences = en_sentences[:TOTAL_SENTENCES]\n",
    "ta_sentences = ta_sentences[:TOTAL_SENTENCES]\n",
    "en_sentences = [sentence.rstrip('\\n').lower() for sentence in en_sentences]\n",
    "ta_sentences = [sentence.rstrip('\\n') for sentence in ta_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 200000\n",
      "Number of valid sentences: 172749\n"
     ]
    }
   ],
   "source": [
    "def is_valid_token(sentence, vocab):\n",
    "    return all(token in vocab for token in sentence)\n",
    "\n",
    "def find_invalid_tokens(sentence, vocab):\n",
    "    return [token for token in set(sentence) if token not in vocab]\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(sentence) <= max_sequence_length\n",
    "\n",
    "invalid_tokens_list = []\n",
    "valid_sentence_indices = []\n",
    "invalid_sentence_indices = []\n",
    "\n",
    "for index, (ta_sentence, en_sentence) in enumerate(zip(ta_sentences, en_sentences)):\n",
    "    invalid_ta_tokens = find_invalid_tokens(ta_sentence, ta_vocab)\n",
    "    invalid_en_tokens = find_invalid_tokens(en_sentence, en_vocab)\n",
    "\n",
    "    if is_valid_length(ta_sentence, 250) and is_valid_length(en_sentence, 250):\n",
    "        if is_valid_token(ta_sentence, ta_vocab) and is_valid_token(en_sentence, en_vocab):\n",
    "            valid_sentence_indices.append(index)\n",
    "        else:\n",
    "            invalid_tokens_list.append((invalid_ta_tokens, invalid_en_tokens))\n",
    "            invalid_sentence_indices.append(index)\n",
    "            \n",
    "print(f\"Number of sentences: {len(ta_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indices)}\")\n",
    "         \n",
    "ta_sentences = [ta_sentences[i] for i in valid_sentence_indices]\n",
    "en_sentences = [en_sentences[i] for i in valid_sentence_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    return list(sentence)\n",
    "\n",
    "def tokens_to_indices(tokens, vocab_to_index):\n",
    "    return [vocab_to_index[token] for token in tokens]\n",
    "\n",
    "def add_special_tokens(indices, sos_token_index, eos_token_index):\n",
    "    return [sos_token_index] + indices + [eos_token_index]\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_sequences(batch, padding_value):\n",
    "    return pad_sequence(batch, batch_first=True, padding_value=padding_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, \n",
    "                 source_vocab_to_index, target_vocab_to_index,\n",
    "                 max_length=250):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.source_vocab_to_index = source_vocab_to_index\n",
    "        self.target_vocab_to_index = target_vocab_to_index\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.source_sos = source_vocab_to_index['<SOS>']\n",
    "        self.source_eos = source_vocab_to_index['<EOS>']\n",
    "        self.source_pad = source_vocab_to_index['<PAD>']\n",
    "        \n",
    "        self.target_sos = target_vocab_to_index['<SOS>']\n",
    "        self.target_eos = target_vocab_to_index['<EOS>']\n",
    "        self.target_pad = target_vocab_to_index['<PAD>']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize sentences\n",
    "        src_tokens = tokenize_sentence(self.source_sentences[idx])\n",
    "        tgt_tokens = tokenize_sentence(self.target_sentences[idx])\n",
    "        \n",
    "        # Convert tokens to indices\n",
    "        src_indices = tokens_to_indices(src_tokens, self.source_vocab_to_index)\n",
    "        tgt_indices = tokens_to_indices(tgt_tokens, self.target_vocab_to_index)\n",
    "        \n",
    "        # Add special tokens\n",
    "        src_indices = add_special_tokens(src_indices, self.source_sos, self.source_eos)\n",
    "        tgt_indices = add_special_tokens(tgt_indices, self.target_sos, self.target_eos)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        src_tensor = torch.tensor(src_indices, dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long)\n",
    "        \n",
    "        return src_tensor, tgt_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=english_to_index['<PAD>'])\n",
    "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=tamil_to_index['<PAD>'])\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = TranslationDataset(\n",
    "    source_sentences=en_sentences,\n",
    "    target_sentences=ta_sentences,\n",
    "    source_vocab_to_index=english_to_index,\n",
    "    target_vocab_to_index=tamil_to_index\n",
    ")\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    num_layers=6,\n",
    "    d_model=512,\n",
    "    dff=2048,\n",
    "    dropout=0.1,\n",
    "    heads=8,\n",
    "    src_vocab_size=len(en_vocab),\n",
    "    tgt_vocab_size=len(ta_vocab),\n",
    "    max_len=252\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'best_model_epoch_24.ptrom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_model_epoch_24.ptrom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36142/3754793641.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "print(f'Model loaded from {MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model, \n",
    "              english_to_index, index_to_tamil, \n",
    "              max_length=250):\n",
    "    model.eval()\n",
    "    tokens = tokenize_sentence(sentence.lower())\n",
    "    indices = tokens_to_indices(tokens, english_to_index)\n",
    "    indices = add_special_tokens(indices, \n",
    "                                 english_to_index[START_TOKEN], \n",
    "                                 english_to_index[END_TOKEN])\n",
    "    src_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    src_padding_mask = create_padding_mask(src_tensor, pad_token=english_to_index[PADDING_TOKEN]).to(device)\n",
    "    tgt_indices = [tamil_to_index[START_TOKEN]]\n",
    "    tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        tgt_padding_mask = create_padding_mask(tgt_tensor, pad_token=tamil_to_index[PADDING_TOKEN]).to(device)\n",
    "        causal_mask = create_causal_mask(tgt_tensor.size(1)).to(device)\n",
    "        combined_mask = combine_masks(tgt_padding_mask, causal_mask)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, tgt_tensor, \n",
    "                          src_padding_mask, \n",
    "                          tgt_padding_mask, \n",
    "                          combined_mask)\n",
    "        \n",
    "        next_token_logits = output[0, -1, :]\n",
    "        _, next_token = torch.max(next_token_logits, dim=-1)\n",
    "        next_token = next_token.item()\n",
    "        tgt_indices.append(next_token)\n",
    "        tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        if next_token == tamil_to_index[END_TOKEN]:\n",
    "            break\n",
    "    \n",
    "    translated_tokens = [index_to_tamil[idx] for idx in tgt_indices[1:] if idx != tamil_to_index[END_TOKEN]]\n",
    "    translated_sentence = ''.join(translated_tokens)\n",
    "    \n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def translate_beam_search(sentence, model, \n",
    "                          english_to_index, index_to_tamil, \n",
    "                          max_length=250, beam_width=3):\n",
    "    \"\"\"\n",
    "    Translates an English sentence to Tamil using Beam Search with the trained Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The English sentence to translate.\n",
    "        model (Transformer): The trained Transformer model.\n",
    "        english_to_index (dict): Mapping from English tokens to indices.\n",
    "        index_to_tamil (dict): Mapping from Tamil indices to tokens.\n",
    "        max_length (int): Maximum length of the generated Tamil sentence.\n",
    "        beam_width (int): The number of beams to keep during decoding.\n",
    "        \n",
    "    Returns:\n",
    "        str: The translated Tamil sentence.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess the input sentence\n",
    "    tokens = tokenize_sentence(sentence.lower())\n",
    "    indices = tokens_to_indices(tokens, english_to_index)\n",
    "    indices = add_special_tokens(indices, \n",
    "                                 english_to_index[START_TOKEN], \n",
    "                                 english_to_index[END_TOKEN])\n",
    "    src_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # Shape: [1, src_seq_len]\n",
    "    \n",
    "    # Create source padding mask\n",
    "    src_padding_mask = create_padding_mask(src_tensor, pad_token=english_to_index[PADDING_TOKEN]).to(device)\n",
    "    \n",
    "    # Initialize the beam with the start token\n",
    "    beams = [([tamil_to_index[START_TOKEN]], 0.0)]  # List of tuples: (sequence, cumulative log-prob)\n",
    "    \n",
    "    completed_beams = []\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        new_beams = []\n",
    "        for seq, score in beams:\n",
    "            # If the last token is <EOS>, add the beam to completed_beams\n",
    "            if seq[-1] == tamil_to_index[END_TOKEN]:\n",
    "                completed_beams.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            # Prepare target tensor\n",
    "            tgt_tensor = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(device)  # Shape: [1, seq_len]\n",
    "            \n",
    "            # Create target padding mask\n",
    "            tgt_padding_mask = create_padding_mask(tgt_tensor, pad_token=tamil_to_index[PADDING_TOKEN]).to(device)\n",
    "            \n",
    "            # Create causal mask for target\n",
    "            causal_mask = create_causal_mask(tgt_tensor.size(1)).to(device)\n",
    "            \n",
    "            # Combine masks\n",
    "            combined_mask = combine_masks(tgt_padding_mask, causal_mask)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            with torch.no_grad():\n",
    "                output = model(src_tensor, tgt_tensor, \n",
    "                              src_padding_mask, \n",
    "                              tgt_padding_mask, \n",
    "                              combined_mask)  # Shape: [1, seq_len, tgt_vocab_size]\n",
    "            \n",
    "            # Get the logits for the last token\n",
    "            next_token_logits = output[0, -1, :]  # Shape: [tgt_vocab_size]\n",
    "            \n",
    "            # Compute log probabilities\n",
    "            log_probs = nn.functional.log_softmax(next_token_logits, dim=-1)  # Shape: [tgt_vocab_size]\n",
    "            \n",
    "            # Get the top `beam_width` tokens and their log probabilities\n",
    "            topk_log_probs, topk_indices = torch.topk(log_probs, beam_width)\n",
    "            \n",
    "            # Expand each beam with each of the top `beam_width` tokens\n",
    "            for i in range(beam_width):\n",
    "                next_token = topk_indices[i].item()\n",
    "                next_log_prob = topk_log_probs[i].item()\n",
    "                new_seq = seq + [next_token]\n",
    "                new_score = score + next_log_prob\n",
    "                new_beams.append((new_seq, new_score))\n",
    "        \n",
    "        # If no new beams are generated, break\n",
    "        if not new_beams:\n",
    "            break\n",
    "        \n",
    "        # Keep the top `beam_width` beams based on cumulative score\n",
    "        beams = heapq.nlargest(beam_width, new_beams, key=lambda x: x[1])\n",
    "        \n",
    "        # If all beams are completed, stop early\n",
    "        if len(completed_beams) >= beam_width:\n",
    "            break\n",
    "    \n",
    "    # If no completed beams, use the current beams\n",
    "    if not completed_beams:\n",
    "        completed_beams = beams\n",
    "    \n",
    "    # Select the beam with the highest score\n",
    "    best_beam = max(completed_beams, key=lambda x: x[1])\n",
    "    tgt_indices = best_beam[0]\n",
    "    \n",
    "    # Convert indices to tokens, excluding <SOS> and <EOS>\n",
    "    translated_tokens = [index_to_tamil[idx] for idx in tgt_indices[1:] if idx != tamil_to_index[END_TOKEN]]\n",
    "    translated_sentence = ''.join(translated_tokens)\n",
    "    \n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: farmers in this region largely grow paddy and wheat.\n",
      "Tamil: இதனால் பல பகுதிகளில் போக்குவரத்து பெரிதும் பாதிக்கப்பட்டுள்ளது.\n"
     ]
    }
   ],
   "source": [
    "english_sentence = \"farmers in this region largely grow paddy and wheat.\"\n",
    "tamil_translation = translate(english_sentence, model, \n",
    "                                english_to_index, index_to_tamil)\n",
    "print(f\"English: {english_sentence}\")\n",
    "print(f\"Tamil: {tamil_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\"How are you?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: How are you?\n",
      "Tamil (Greedy): யார் இருக்கா?\n",
      "Tamil (Beam Search): எப்படி இருக்கிறாய்?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for english_sentence in test_sentences:\n",
    "    tamil_translation_greedy = translate(english_sentence, model, \n",
    "                                        english_to_index, index_to_tamil)\n",
    "    tamil_translation_beam = translate_beam_search(english_sentence, model, \n",
    "                                                    english_to_index, index_to_tamil, \n",
    "                                                    beam_width=3)\n",
    "    print(f\"English: {english_sentence}\")\n",
    "    print(f\"Tamil (Greedy): {tamil_translation_greedy}\")\n",
    "    print(f\"Tamil (Beam Search): {tamil_translation_beam}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
